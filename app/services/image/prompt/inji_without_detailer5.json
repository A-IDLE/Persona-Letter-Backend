{
  "1": {
    "inputs": {
      "ckpt_name": "revAnimated_v122EOL.safetensors"
    },
    "class_type": "CheckpointLoaderSimple",
    "_meta": {
      "title": "Load Checkpoint"
    }
  },
  "2": {
    "inputs": {
      "stop_at_clip_layer": -2,
      "clip": [
        "1",
        1
      ]
    },
    "class_type": "CLIPSetLastLayer",
    "_meta": {
      "title": "CLIP Set Last Layer"
    }
  },
  "3": {
    "inputs": {
      "text": "<lora:EmmaWatson:0.75>, 1girl, brown eyes, digital painting, bushy brown hair, brown eyes, masterpiece, 8k, perfect artwork, ray tracing, <lora:harry_potter_v1:0.2>",
      "clip": [
        "16",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "Positive"
    }
  },
  "4": {
    "inputs": {
      "text": "nsfw, (worst quality:1.2), (low quality:1.2), (lowres:1.1), (monochrome:1.1), (greyscale),deformed, bad anatomy, disfigured, poorly drawn face, mutation, mutated, extra limb, ugly, disgusting, missing limb, floating limbs, disconnected limbs, malformed hands, blurry, doubled face, mutated hands,mutated fingers, multiple eyebrows, bad feet, bad leg, ((extra feet)), ((extra legs)), extra fingers, extra breast, watermark, username, signature, logo, multiple views, sketch, child, child face, midriff, abs, beard, facial hair, badhandsv5-neg, EasyNegative",
      "clip": [
        "16",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "5": {
    "inputs": {
      "seed": 201013139309507,
      "steps": 30,
      "cfg": 7,
      "sampler_name": "dpmpp_2m",
      "scheduler": "karras",
      "denoise": 1,
      "model": [
        "16",
        0
      ],
      "positive": [
        "3",
        0
      ],
      "negative": [
        "4",
        0
      ],
      "latent_image": [
        "6",
        0
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "Sampler"
    }
  },
  "6": {
    "inputs": {
      "width": 496,
      "height": 760,
      "batch_size": 1
    },
    "class_type": "EmptyLatentImage",
    "_meta": {
      "title": "Empty Latent Image"
    }
  },
  "7": {
    "inputs": {
      "samples": [
        "15",
        0
      ],
      "vae": [
        "8",
        0
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "8": {
    "inputs": {
      "vae_name": "taesd"
    },
    "class_type": "VAELoader",
    "_meta": {
      "title": "Load VAE"
    }
  },
  "10": {
    "inputs": {
      "tile_size": 512,
      "samples": [
        "5",
        0
      ],
      "vae": [
        "8",
        0
      ]
    },
    "class_type": "VAEDecodeTiled",
    "_meta": {
      "title": "VAE Decode (Tiled)"
    }
  },
  "11": {
    "inputs": {
      "model_name": "8xNMKDSuperscale_150000G.pt"
    },
    "class_type": "UpscaleModelLoader",
    "_meta": {
      "title": "Load Upscale Model"
    }
  },
  "12": {
    "inputs": {
      "upscale_model": [
        "11",
        0
      ],
      "image": [
        "10",
        0
      ]
    },
    "class_type": "ImageUpscaleWithModel",
    "_meta": {
      "title": "Upscale Image (using Model)"
    }
  },
  "13": {
    "inputs": {
      "upscale_method": "nearest-exact",
      "width": 492,
      "height": 760,
      "crop": "disabled",
      "image": [
        "12",
        0
      ]
    },
    "class_type": "ImageScale",
    "_meta": {
      "title": "Upscale Image"
    }
  },
  "14": {
    "inputs": {
      "tile_size": 512,
      "pixels": [
        "13",
        0
      ],
      "vae": [
        "8",
        0
      ]
    },
    "class_type": "VAEEncodeTiled",
    "_meta": {
      "title": "VAE Encode (Tiled)"
    }
  },
  "15": {
    "inputs": {
      "seed": 415242878603566,
      "steps": 30,
      "cfg": 7,
      "sampler_name": "dpmpp_2m",
      "scheduler": "karras",
      "denoise": 0.48,
      "model": [
        "16",
        0
      ],
      "positive": [
        "3",
        0
      ],
      "negative": [
        "4",
        0
      ],
      "latent_image": [
        "14",
        0
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "Sampler2"
    }
  },
  "16": {
    "inputs": {
      "lora_name": "harry_potter_v1.safetensors",
      "strength_model": 1,
      "strength_clip": 1,
      "model": [
        "17",
        0
      ],
      "clip": [
        "17",
        1
      ]
    },
    "class_type": "LoraLoader",
    "_meta": {
      "title": "Load LoRA"
    }
  },
  "17": {
    "inputs": {
      "lora_name": "EmmaWatson.safetensors",
      "strength_model": 1,
      "strength_clip": 1,
      "model": [
        "1",
        0
      ],
      "clip": [
        "2",
        0
      ]
    },
    "class_type": "LoraLoader",
    "_meta": {
      "title": "Load LoRA"
    }
  },
  "22": {
    "inputs": {
      "filename_prefix": "ComfyUI",
      "images": [
        "7",
        0
      ]
    },
    "class_type": "SaveImageWithS3Upload",
    "_meta": {
      "title": "Save Image With S3 Upload"
    }
  }
}